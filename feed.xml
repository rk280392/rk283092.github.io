<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://rk280392.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rk280392.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-09-16T13:31:52+00:00</updated><id>https://rk280392.github.io/feed.xml</id><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How to stream k3s journal logs to CloudWatch on Rancher</title><link href="https://rk280392.github.io/blog/2023/k3s-logs-to-cloudWatch/" rel="alternate" type="text/html" title="How to stream k3s journal logs to CloudWatch on Rancher"/><published>2023-09-10T17:40:16+00:00</published><updated>2023-09-10T17:40:16+00:00</updated><id>https://rk280392.github.io/blog/2023/k3s-logs-to-cloudWatch</id><content type="html" xml:base="https://rk280392.github.io/blog/2023/k3s-logs-to-cloudWatch/"><![CDATA[<h3 id="requirements">Requirements:</h3> <ul> <li>Gather k3s journal logs from each node in the cluster.</li> <li>Parse the logs to forward only the required fields.</li> <li>Forward the parsed data to cloudwatch.</li> </ul> <h3 id="solution">Solution:</h3> <p>Rancher uses this <a href="https://kube-logging.github.io/docs/">logging operator</a> that comes with the below CRDS:</p> <ul> <li>flow</li> <li>clusterFlow</li> <li>output</li> <li>clusterOutput</li> </ul> <p>You can read more about them <a href="https://kube-logging.github.io/docs/configuration/">here</a></p> <p>We will be using clusterFlow and clusterOutput as they are not namespaced. The clusterFlow CRD defines a logging flow for Fluentd with filters and outputs. Using this, we can define and apply filters to select only the desired data. Once parsed, data will be forwarded to the clusterOutput object. The clusterOutput CRD defines where to send the data. It supports several <a href="https://banzaicloud.com/docs/one-eye/logging-operator/plugins/outputs/">plugins</a>, but we will use Cloudwatch. You can read the spec <a href="https://banzaicloud.com/docs/one-eye/logging-operator/plugins/outputs/cloudwatch/">here</a>.</p> <p>Now we have clusterFlow to parse the data and clusterOutput to define the destination of data. We need a way to get the journal logs from the nodes.</p> <p><a href="https://banzaicloud.com/docs/one-eye/logging-operator/configuration/crds/extensions/">HostTailer</a> CRD is provided by https://banzaicloud.com/ and is supported on the Rancher. From the doc, <code class="language-plaintext highlighter-rouge">HostTailerâ€™s main goal is to tail custom files and transmit their changes to stdout.</code> This way, the logging-operator can process them. An example usage is provided <a href="https://banzaicloud.com/docs/one-eye/logging-operator/configuration/extensions/kubernetes-host-tailer/">here</a>.</p> <p>Similarly, you can use the <a href="https://banzaicloud.com/docs/one-eye/logging-operator/configuration/extensions/kubernetes-host-tailer/#create-file-tailer">file-tailer</a> if you know the log file name.</p> <p>The difference between the two is host-tailer looks at specific systemd service logs like k3s.service logs, while for file-tailer, you need to specify the exact location of the log file like /var/log/nginx/access.log.</p> <p>Here is the YAML to get the systemd journal logs from each host. This will create a daemonset. Pods will fetch the logs from the journal log files of the specified service name and output them to stdout.</p> <pre><code class="language-SHELL">apiVersion: logging-extensions.banzaicloud.io/v1alpha1
kind: HostTailer
metadata:
  name: k3s-systemd-tailer
  namespace: cattle-logging-system
spec:
  systemdTailers:
    - name: k3s-systemd-tailer
      maxEntries: 100
      path: /run/log/journal/
      systemdFilter: k3s.service
</code></pre> <p>The log output will then be fed to clusterFlow, which parses the logs.</p> <pre><code class="language-SHELL">apiVersion: logging.banzaicloud.io/v1beta1
kind: ClusterFlow
metadata:
  name: host-tailer-flow
  namespace: cattle-logging-system
spec:
  filters:
    - parser:
        key_name: message
        reserve_time: true
        parse:
          type: json
    - record_transformer:
        remove_keys: _CMDLINE,_BOOT_ID,_MACHINE_ID,PRIORITY,SYSLOG_FACILITY,_UID,_GID,_SELINUX_CONTEXT,_SYSTEMD_SLICE,_CAP_EFFECTIVE,_TRANSPORT,_SYSTEMD_CGROUP,_SYSTEMD_INVOCATION_ID,_STREAM_ID,SYSLOG_IDENTIFIER,_COMM,_EXE
  match:
    - select: 
        labels:
          app.kubernetes.io/name: host-tailer
  globalOutputRefs:
    - host-logging-cloudwatch
</code></pre> <p>Here we are matching the app name to the name of the host-tailer daemonset, which is host-tailer. Once matched, we are parsing them using the <a href="https://docs.fluentd.org/filter/parser">parser</a> plugin. We only need the <strong>message</strong> field from the logs, so <strong>key_name</strong> is specified as <strong>message</strong>, and <strong>parse</strong> type is set to <strong>json</strong>. After this, we remove unwanted fields from the message field using the remove_keys spec from the <a href="https://docs.fluentd.org/filter/record_transformer">record_transformer</a> plugin.</p> <p>The globalOutputRefs is set to the name of the clusterOutput.</p> <pre><code class="language-SHELL">apiVersion: logging.banzaicloud.io/v1beta1
kind: ClusterOutput
metadata:
  name: host-logging-cloudwatch
  namespace: cattle-logging-system
spec:
  cloudwatch:
    auto_create_stream: true
    format:
      type: json
    buffer:
      timekey: 30s
      timekey_use_utc: true
      timekey_wait: 30s
    log_group_name: hosted-group
    log_stream_name: host-logs
    region: aws-region
</code></pre> <p>In the clusterOutput spec, we use cloudwatch with log_group_name, log_stream_name, and region values passed a variable.</p>]]></content><author><name></name></author><category term="k3s"/><category term="journal"/><category term="logging"/><summary type="html"><![CDATA[logging flow for Fluentd with filters and outputs]]></summary></entry></feed>